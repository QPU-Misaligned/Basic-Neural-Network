{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basicNeuralNetworkR3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QPU-Misaligned/Basic-Neural-Network/blob/Release-3/basicNeuralNetworkR3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pSdkNhPn8oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Originally created 2/14/19 by QPU Misaligned\n",
        "#Release 3 created 6/22/19 by QPU Misaligned\n",
        "#https://github.com/QPU-Misaligned/Basic-Neural-Network\n",
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "class basicNeuralNet:\n",
        "  #__init__ method\n",
        "  def __init__(self, nodesPerLayer, learningRate):\n",
        "    self.nodesPerLayer = nodesPerLayer\n",
        "    self.learningRate = learningRate\n",
        "    self.activationFunction = self.ELU\n",
        "    self.dx = 0.0000000001\n",
        "    weights = []\n",
        "    for i in range(0, len(nodesPerLayer)-1):\n",
        "      layerWeights = []\n",
        "      for j in range(0, nodesPerLayer[i+1]):\n",
        "        nodeWeights = []\n",
        "        for k in range(0, nodesPerLayer[i]):\n",
        "          nodeWeights.append(random.random())\n",
        "        layerWeights.append(nodeWeights)\n",
        "      weights.append(layerWeights)\n",
        "    biases = []\n",
        "    for i in range(0, len(nodesPerLayer)-1):\n",
        "      layerBiases = []\n",
        "      for j in range(0, nodesPerLayer[i+1]):\n",
        "        layerBiases.append([random.random()])\n",
        "      biases.append(layerBiases)\n",
        "    self.weightsBiases = [weights, biases]\n",
        "    weightsV = []\n",
        "    for i in range(0, len(nodesPerLayer)-1):\n",
        "      layerWeightsV = []\n",
        "      for j in range(0, nodesPerLayer[i+1]):\n",
        "        nodeWeightsV = []\n",
        "        for k in range(0, nodesPerLayer[i]):\n",
        "          nodeWeightsV.append(0)\n",
        "        layerWeightsV.append(nodeWeightsV)\n",
        "      weightsV.append(layerWeightsV)\n",
        "    biasesV = []\n",
        "    for i in range(0, len(nodesPerLayer)-1):\n",
        "      layerBiasesV = []\n",
        "      for j in range(0, nodesPerLayer[i+1]):\n",
        "        layerBiasesV.append([0])\n",
        "      biasesV.append(layerBiases)\n",
        "    self.weightsBiasesV = [weightsV, biasesV]\n",
        "  \n",
        "  #getters and setters\n",
        "  def getNodesPerLayer(self):\n",
        "    return self.nodesPerLayer\n",
        "  \n",
        "  def getLearningRate(self):\n",
        "    return self.learningRate\n",
        "  \n",
        "  def setLearningRate(self, learningRate):\n",
        "    self.learningRate = learningRate\n",
        "  \n",
        "  def getWeightsBiases(self):\n",
        "    return self.weightsBiases\n",
        "  \n",
        "  def setWeightsBiases(self, weightsBiases):\n",
        "    self.weightsBiases = weightsBiases\n",
        "  \n",
        "  def getActivationFunction(self):\n",
        "    return self.activationFunction\n",
        "  \n",
        "  def setActivationFunction(self, activationFunction):\n",
        "    self.activationFunction = activationFunction\n",
        "  \n",
        "  #getters and setters for individual weights/biases\n",
        "  def getWeightBias(self, weightsBiases, location):\n",
        "    output = []\n",
        "    subArray = weightsBiases[:]\n",
        "    for i in location:\n",
        "      output.append(subArray)\n",
        "      subArray = subArray[i]\n",
        "    output.append(subArray)\n",
        "    return output\n",
        "  \n",
        "  def setWeightBias(self, weightsBiases, location, inputValue):\n",
        "    subArrays = self.getWeightBias(weightsBiases, location)\n",
        "    subArrays[-1] = inputValue\n",
        "    for i in range(0, len(subArrays)-1):\n",
        "      subArrays[len(subArrays)-i-2][location[len(subArrays)-i-2]] = subArrays[len(subArrays)-i-1]\n",
        "    weightsBiases = subArrays[0]\n",
        "    return subArrays\n",
        "  \n",
        "  #activation functions\n",
        "  def linear(self, inputValue):\n",
        "    return inputValue\n",
        "  \n",
        "  def sigmoid(self, inputValue):\n",
        "    return 1/(1+math.exp(-1*inputValue))\n",
        "  \n",
        "  def tanh(self, inputValue):\n",
        "    return (math.exp(inputValue)-math.exp(-1*inputValue))/(math.exp(inputValue)+math.exp(-1*inputValue))\n",
        "  \n",
        "  def ReLU(self, inputValue):\n",
        "    if(inputValue>0):\n",
        "      return inputValue\n",
        "    return 0\n",
        "  \n",
        "  def LReLU(self, inputValue):\n",
        "    if(inputValue>0):\n",
        "      return inputValue\n",
        "    return 0.01*inputValue\n",
        "  \n",
        "  def ELU(self, inputValue):\n",
        "    if(inputValue>0):\n",
        "      return inputValue\n",
        "    return math.exp(inputValue)-1\n",
        "  \n",
        "  def SReLU(self, inputValue):\n",
        "    return math.log(1+math.exp(inputValue))\n",
        "  \n",
        "  def SLReLU(self, inputValue):\n",
        "    return 0.01*inputValue+(0.99)*math.log(1+math.exp(inputValue))\n",
        "  \n",
        "  def SELU(self, inputValue):\n",
        "    return math.log(1+math.exp(inputValue+1))-1\n",
        "  \n",
        "  #node output and network output methods\n",
        "  def nodeOutputA(self, inputValues, inputWeights, inputBias, activationFunction):\n",
        "    aggregate = inputBias\n",
        "    for i in range(0, len(inputValues)):\n",
        "      aggregate += inputValues[i]*inputWeights[i]\n",
        "    return activationFunction(aggregate)\n",
        "  \n",
        "  def nodeOutput(self, inputValues, inputWeights, inputBias):\n",
        "    return self.nodeOutputA(inputValues, inputWeights, inputBias, self.activationFunction)\n",
        "  \n",
        "  def networkOutputA(self, inputValues, activationFunction):\n",
        "    layerInput = inputValues[:]\n",
        "    for i in range(0, len(self.nodesPerLayer)-1):\n",
        "      layerOutput = []\n",
        "      for j in range(0, self.nodesPerLayer[i+1]):\n",
        "        layerOutput.append(self.nodeOutputA(layerInput, self.weightsBiases[0][i][j], self.weightsBiases[1][i][j][0], activationFunction))\n",
        "      layerInput = layerOutput[:]\n",
        "    return layerOutput\n",
        "  \n",
        "  def networkOutput(self, inputValues):\n",
        "    return self.networkOutputA(inputValues, self.activationFunction)\n",
        "  \n",
        "  #cost function for a dataset\n",
        "  def costA(self, dataSet, activationFunction):\n",
        "    sum = 0\n",
        "    for dataPoint in dataSet:\n",
        "      networkOutput = self.networkOutputA(dataPoint[0], activationFunction)\n",
        "      for i in range(0, len(networkOutput)):\n",
        "        sum += (networkOutput[i]-dataPoint[1][i])**2\n",
        "    return sum\n",
        "  \n",
        "  def cost(self, dataSet):\n",
        "    return self.costA(dataSet, self.activationFunction)\n",
        "  \n",
        "  #gradient finding function for a dataset\n",
        "  def gradientA(self, weightsBiases, dataSet, activationFunction):\n",
        "    gradient = []\n",
        "    costZero = self.costA(dataSet, activationFunction)\n",
        "    for weightOrBias in range(0, len(self.weightsBiases)):\n",
        "      for layer in range(0, len(self.weightsBiases[weightOrBias])):\n",
        "        for node in range(0, len(self.weightsBiases[weightOrBias][layer])):\n",
        "          for weightBiasValue in range(0, len(self.weightsBiases[weightOrBias][layer][node])):\n",
        "            weightBiasZero = self.weightsBiases[weightOrBias][layer][node][weightBiasValue]\n",
        "            self.setWeightBias(weightsBiases, [weightOrBias, layer, node, weightBiasValue], weightBiasZero+self.dx)\n",
        "            gradient.append((self.costA(dataSet, activationFunction)-costZero)/self.dx)\n",
        "            self.setWeightBias(weightsBiases, [weightOrBias, layer, node, weightBiasValue], weightBiasZero)\n",
        "    return gradient\n",
        "  \n",
        "  def gradient(self, dataSet):\n",
        "    return self.gradientA(self. weightsBiases, dataSet, self.activationFunction)\n",
        "  \n",
        "  #optimize with stochastic gradient descent function for a dataset 1st order\n",
        "  def optimizeSGDA(self, weightsBiases, dataSet, activationFunction):\n",
        "    g = self.gradientA(weightsBiases, dataSet, activationFunction)\n",
        "    i = 0\n",
        "    for weightOrBias in range(0, len(weightsBiases)):\n",
        "      for layer in range(0, len(weightsBiases[weightOrBias])):\n",
        "        for node in range(0, len(weightsBiases[weightOrBias][layer])):\n",
        "          for weightBiasValue in range(0, len(weightsBiases[weightOrBias][layer][node])):\n",
        "            self.setWeightBias(weightsBiases, [weightOrBias, layer, node, weightBiasValue], weightsBiases[weightOrBias][layer][node][weightBiasValue]-self.learningRate*g[i])\n",
        "            i += 1\n",
        "    return self.costA(dataSet, activationFunction)\n",
        "  \n",
        "  def optimizeSGD(self, dataSet):\n",
        "    return self.optimizeSGDA(self.weightsBiases, dataSet, self.activationFunction)\n",
        "  \n",
        "  #optimize with momentum for a dataset 2nd order\n",
        "  def optimizeMomentumA(self, weightsBiasesV, weightsBiases, dataSet, activationFunction, friction):\n",
        "    g = self.gradientA(weightsBiases, dataSet, activationFunction)\n",
        "    i = 0\n",
        "    for weightOrBias in range(0, len(weightsBiasesV)):\n",
        "      for layer in range(0, len(weightsBiasesV[weightOrBias])):\n",
        "        for node in range(0, len(weightsBiasesV[weightOrBias][layer])):\n",
        "          for weightBiasValue in range(0, len(weightsBiasesV[weightOrBias][layer][node])):\n",
        "            self.setWeightBias(weightsBiasesV, [weightOrBias, layer, node, weightBiasValue], (1-friction)*weightsBiasesV[weightOrBias][layer][node][weightBiasValue]+self.learningRate*g[i])\n",
        "            self.setWeightBias(weightsBiases, [weightOrBias, layer, node, weightBiasValue], weightsBiases[weightOrBias][layer][node][weightBiasValue]-self.learningRate*weightsBiasesV[weightOrBias][layer][node][weightBiasValue])\n",
        "            i+=1\n",
        "    return self.costA(dataSet, activationFunction)\n",
        "  \n",
        "  def optimizeMomentum(self, dataSet, friction):\n",
        "    return self.optimizeMomentumA(self.weightsBiasesV, self.weightsBiases, dataSet, self.activationFunction, friction)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
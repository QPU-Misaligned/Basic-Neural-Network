{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basicNeuralNetworkR2_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "DeBEaS93rR3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Originally created 2/14/19 by QPU Misaligned \n",
        "#Release 2.1 created 3/1/19 by QPU Misaligned\n",
        "#https://github.com/QPU-Misaligned/Basic-Neural-Network\n",
        "\n",
        "import math\n",
        "import random\n",
        "\n",
        "class basicNeuralNet:\n",
        "  #__init__ method\n",
        "  def __init__(self, nodesPerLayer, learningRate):\n",
        "    self.nodesPerLayer = nodesPerLayer\n",
        "    self.learningRate = learningRate\n",
        "    self.activationFunction = self.ELU\n",
        "    self.dx = 0.0000000001\n",
        "    weights = []\n",
        "    for i in range(0, len(nodesPerLayer)-1):\n",
        "      layerWeights = []\n",
        "      for j in range(0, nodesPerLayer[i+1]):\n",
        "        nodeWeights = []\n",
        "        for k in range(0, nodesPerLayer[i]):\n",
        "          nodeWeights.append(random.random())\n",
        "        layerWeights.append(nodeWeights)\n",
        "      weights.append(layerWeights)\n",
        "    biases = []\n",
        "    for i in range(0, len(nodesPerLayer)-1):\n",
        "      layerBiases = []\n",
        "      for j in range(0, nodesPerLayer[i+1]):\n",
        "        layerBiases.append([random.random()])\n",
        "      biases.append(layerBiases)\n",
        "    self.weightsBiases = [weights, biases]\n",
        "  \n",
        "  #getters and setters\n",
        "  def getNodesPerLayer(self):\n",
        "    return self.nodesPerLayer\n",
        "  \n",
        "  def getLearningRate(self):\n",
        "    return self.learningRate\n",
        "  \n",
        "  def setLearningRate(self, learningRate):\n",
        "    self.learningRate = learningRate\n",
        "  \n",
        "  def getWeightsBiases(self):\n",
        "    return self.weightsBiases\n",
        "  \n",
        "  def setWeightsBiases(self, weightsBiases):\n",
        "    self.weightsBiases = weightsBiases\n",
        "  \n",
        "  def getActivationFunction(self):\n",
        "    return self.activationFunction\n",
        "  \n",
        "  def setActivationFunction(self, activationFunction):\n",
        "    self.activationFunction = activationFunction\n",
        "  \n",
        "  #getters and setters for individual weights/biases\n",
        "  def getWeightBias(self, location):\n",
        "    output = []\n",
        "    subArray = self.weightsBiases[:]\n",
        "    for i in location:\n",
        "      output.append(subArray)\n",
        "      subArray = subArray[i]\n",
        "    output.append(subArray)\n",
        "    return output\n",
        "  \n",
        "  def setWeightBias(self, location, inputValue):\n",
        "    subArrays = self.getWeightBias(location)\n",
        "    subArrays[-1] = inputValue\n",
        "    for i in range(0, len(subArrays)-1):\n",
        "      subArrays[len(subArrays)-i-2][location[len(subArrays)-i-2]] = subArrays[len(subArrays)-i-1]\n",
        "    self.weightsBiases = subArrays[0]\n",
        "    return subArrays\n",
        "  \n",
        "  #activation functions\n",
        "  def linear(self, inputValue):\n",
        "    return inputValue\n",
        "  \n",
        "  def sigmoid(self, inputValue):\n",
        "    return 1/(1+math.exp(-1*inputValue))\n",
        "  \n",
        "  def tanh(self, inputValue):\n",
        "    return (math.exp(inputValue)-math.exp(-1*inputValue))/(math.exp(inputValue)+math.exp(-1*inputValue))\n",
        "  \n",
        "  def ReLU(self, inputValue):\n",
        "    if(inputValue>0):\n",
        "      return inputValue\n",
        "    return 0\n",
        "  \n",
        "  def LReLU(self, inputValue):\n",
        "    if(inputValue>0):\n",
        "      return inputValue\n",
        "    return 0.01*inputValue\n",
        "  \n",
        "  def ELU(self, inputValue):\n",
        "    if(inputValue>0):\n",
        "      return inputValue\n",
        "    return math.exp(inputValue)-1\n",
        "  \n",
        "  def SReLU(self, inputValue):\n",
        "    return math.log(1+math.exp(inputValue))\n",
        "  \n",
        "  def SLReLU(self, inputValue):\n",
        "    return 0.01*inputValue+(0.99)*math.log(1+math.exp(inputValue))\n",
        "  \n",
        "  def SELU(self, inputValue):\n",
        "    return math.log(1+math.exp(inputValue+1))-1\n",
        "  \n",
        "  #node output and network output methods\n",
        "  def nodeOutputA(self, inputValues, inputWeights, inputBias, activationFunction):\n",
        "    aggregate = inputBias\n",
        "    for i in range(0, len(inputValues)):\n",
        "      aggregate += inputValues[i]*inputWeights[i]\n",
        "    return activationFunction(aggregate)\n",
        "  \n",
        "  def nodeOutput(self, inputValues, inputWeights, inputBias):\n",
        "    return self.nodeOutputA(inputValues, inputWeights, inputBias, self.activationFunction)\n",
        "  \n",
        "  def networkOutputA(self, inputValues, activationFunction):\n",
        "    layerInput = inputValues[:]\n",
        "    for i in range(0, len(self.nodesPerLayer)-1):\n",
        "      layerOutput = []\n",
        "      for j in range(0, self.nodesPerLayer[i+1]):\n",
        "        layerOutput.append(self.nodeOutputA(layerInput, self.weightsBiases[0][i][j], self.weightsBiases[1][i][j][0], activationFunction))\n",
        "      layerInput = layerOutput[:]\n",
        "    return layerOutput\n",
        "  \n",
        "  def networkOutput(self, inputValues):\n",
        "    return self.networkOutputA(inputValues, self.activationFunction)\n",
        "  \n",
        "  #cost function for a dataset\n",
        "  def costA(self, dataSet, activationFunction):\n",
        "    sum = 0\n",
        "    for dataPoint in dataSet:\n",
        "      networkOutput = self.networkOutputA(dataPoint[0], activationFunction)\n",
        "      for i in range(0, len(networkOutput)):\n",
        "        sum += (networkOutput[i]-dataPoint[1][i])**2\n",
        "    return sum\n",
        "  \n",
        "  def cost(self, dataSet):\n",
        "    return self.costA(dataSet, self.activationFunction)\n",
        "  \n",
        "  #gradient finding function for a dataset\n",
        "  def gradientA(self, dataSet, activationFunction):\n",
        "    gradient = []\n",
        "    costZero = self.costA(dataSet, activationFunction)\n",
        "    for weightOrBias in range(0, len(self.weightsBiases)):\n",
        "      for layer in range(0, len(self.weightsBiases[weightOrBias])):\n",
        "        for node in range(0, len(self.weightsBiases[weightOrBias][layer])):\n",
        "          for weightBiasValue in range(0, len(self.weightsBiases[weightOrBias][layer][node])):\n",
        "            weightBiasZero = self.weightsBiases[weightOrBias][layer][node][weightBiasValue]\n",
        "            self.setWeightBias([weightOrBias, layer, node, weightBiasValue], weightBiasZero+self.dx)\n",
        "            gradient.append((self.costA(dataSet, activationFunction)-costZero)/self.dx)\n",
        "            self.setWeightBias([weightOrBias, layer, node, weightBiasValue], weightBiasZero)\n",
        "    return gradient\n",
        "  \n",
        "  def gradient(self, dataSet):\n",
        "    return self.gradientA(dataSet, self.activationFunction)\n",
        "  \n",
        "  #optimize function for a dataset\n",
        "  def optimizeA(self, dataSet, activationFunction):\n",
        "    g = self.gradientA(dataSet, activationFunction)\n",
        "    i = 0\n",
        "    for weightOrBias in range(0, len(self.weightsBiases)):\n",
        "      for layer in range(0, len(self.weightsBiases[weightOrBias])):\n",
        "        for node in range(0, len(self.weightsBiases[weightOrBias][layer])):\n",
        "          for weightBiasValue in range(0, len(self.weightsBiases[weightOrBias][layer][node])):\n",
        "            self.setWeightBias([weightOrBias, layer, node, weightBiasValue], self.weightsBiases[weightOrBias][layer][node][weightBiasValue]-self.learningRate*g[i])\n",
        "            i += 1\n",
        "    return self.costA(dataSet, activationFunction)\n",
        "  \n",
        "  def optimize(self, dataSet):\n",
        "    return self.optimizeA(dataSet, self.activationFunction)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
